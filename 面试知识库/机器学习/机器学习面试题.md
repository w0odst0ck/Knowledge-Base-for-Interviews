| 标记  | 题目                                                                                                                                 | 难度  | 标签                                                                                                                                                                                                                                                                                                                                                                             |
| --- | ---------------------------------------------------------------------------------------------------------------------------------- | --- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
|     |                                                                                                                                    |     |                                                                                                                                                                                                                                                                                                                                                                                |
|     | [说说你了解的机器学习是什么？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834636393746433)                                  | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[人工智能](https://www.mianshiya.com/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)<br><br>[基础理论](https://www.mianshiya.com/tag/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA)                                                                                                                                 |
|     | [监督学习、半监督学习和无监督学习分别是什么，它们的区别在哪？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834636670570497)                  | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[人工智能](https://www.mianshiya.com/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)<br><br>[基础理论](https://www.mianshiya.com/tag/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA)                                                                                                                                 |
|     | [机器学习有哪些常见的算法？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834636993531906)                                   | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[人工智能](https://www.mianshiya.com/tag/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD)<br><br>[基础理论](https://www.mianshiya.com/tag/%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA)                                                                                                                                 |
|     | [什么是损失函数？有什么作用？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834637232607233)                                  | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[损失函数](https://www.mianshiya.com/tag/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0)                                                                                                                                                                                                                   |
|     | [什么是梯度下降？它的工作原理是什么？有哪些变体？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834637496848385)                        | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[梯度下降](https://www.mianshiya.com/tag/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)                                                                                                                                                                                                                   |
|     | [分别解释高斯牛顿法和拟牛顿法。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834637828198402)                                 | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[高斯牛顿法](https://www.mianshiya.com/tag/%E9%AB%98%E6%96%AF%E7%89%9B%E9%A1%BF%E6%B3%95)<br><br>[拟牛顿法](https://www.mianshiya.com/tag/%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95)                                                                                                                       |
|     | [请解释过拟合和欠拟合，并讨论如何应对过拟合问题。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834638096633857)                        | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[过拟合](https://www.mianshiya.com/tag/%E8%BF%87%E6%8B%9F%E5%90%88)<br><br>[欠拟合](https://www.mianshiya.com/tag/%E6%AC%A0%E6%8B%9F%E5%90%88)                                                                                                                                                     |
|     | [什么是正则化？正则化有哪些作用？说说机器学习中常见的正则化方法。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834638365069314)                | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[正则化](https://www.mianshiya.com/tag/%E6%AD%A3%E5%88%99%E5%8C%96)                                                                                                                                                                                                                             |
|     | [线性回归和逻辑回归有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834638633504769)                                 | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[分类与回归](https://www.mianshiya.com/tag/%E5%88%86%E7%B1%BB%E4%B8%8E%E5%9B%9E%E5%BD%92)<br><br>[线性回归](https://www.mianshiya.com/tag/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92)<br><br>[逻辑回归](https://www.mianshiya.com/tag/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)                                     |
|     | [什么是线性回归，请解释其假设和工作原理。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834638914523138)                            | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[线性回归](https://www.mianshiya.com/tag/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92)                                                                                                                                                                                                                   |
|     | [进行线性回归前，为什么需要对特征进行离散化处理？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834639191347202)                        | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[线性回归](https://www.mianshiya.com/tag/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92)                                                                                                                                                                                                                   |
|     | [分别解释 Ridge 回归和 Lasson 回归。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834639459782658)                       | 中等  | [Ridge 回归和 Lasson 回归](https://www.mianshiya.com/tag/Ridge%20%E5%9B%9E%E5%BD%92%E5%92%8C%20Lasson%20%E5%9B%9E%E5%BD%92)                                                                                                                                                                                                                                                         |
|     | [逻辑回归分别是怎样处理二分类问题和多分类问题的？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834639736606721)                        | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[分类](https://www.mianshiya.com/tag/%E5%88%86%E7%B1%BB)<br><br>[逻辑回归](https://www.mianshiya.com/tag/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)                                                                                                                                                     |
|     | [在逻辑回归中是否需要使用交叉验证？为什么？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834640038596609)                           | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[逻辑回归](https://www.mianshiya.com/tag/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)<br><br>[交叉验证](https://www.mianshiya.com/tag/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81)                                                                                                                                 |
|     | [为什么逻辑回归采用交叉熵损失函数，而不是平方损失函数？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834640302837762)                     | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[逻辑回归](https://www.mianshiya.com/tag/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)<br><br>[损失函数](https://www.mianshiya.com/tag/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0)                                                                                                                                 |
|     | [解释 Sigmoid 函数，以及它在逻辑回归中的作用。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834640583856129)                     | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[逻辑回归](https://www.mianshiya.com/tag/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92)<br><br>[Sigmoid 函数](https://www.mianshiya.com/tag/Sigmoid%20%E5%87%BD%E6%95%B0)                                                                                                                                   |
|     | [简单介绍一下 KNN 算法过程。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834640831320065)                                | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [说说 KNN 算法中多数投票的规则。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834641087172609)                              | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [KNN 算法中 K 的取值是如何确定的？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834641389162498)                            | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [KNN 算法分别有哪些优缺点？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834641670180865)                                 | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [KNN 算法有一个显著的缺点，就是计算量太大，可以采用什么方式应对这个问题？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834641942810626)          | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [KNN 算法是如何应对维度灾难的？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834642244800514)                               | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                             |
|     | [KNN 算法和 K-means 算法有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834642555179009)                        | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[K-means 算法](https://www.mianshiya.com/tag/K-means%20%E7%AE%97%E6%B3%95)<br><br>[KNN 算法](https://www.mianshiya.com/tag/KNN%20%E7%AE%97%E6%B3%95)                                                                                                                                             |
|     | [有哪些常见的方法度量点到中心的距离？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834642815225858)                              | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[距离度量](https://www.mianshiya.com/tag/%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F)                                                                                                                                                                                                                   |
|     | [K-means 聚类中每个聚类中心的初始点如何选择？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834643079467009)                      | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[K-means 算法](https://www.mianshiya.com/tag/K-means%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                     |
|     | [如何处理 K-means 中的空聚类？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834643331125250)                             | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[K-means 算法](https://www.mianshiya.com/tag/K-means%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                     |
|     | [K-means 是否会陷入一直寻找聚类中心的循环中？如果是，如何应对？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834643612143617)             | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[K-means 算法](https://www.mianshiya.com/tag/K-means%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                     |
|     | [解释高斯混合模型。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834643876384770)                                       | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[聚类](https://www.mianshiya.com/tag/%E8%81%9A%E7%B1%BB)<br><br>[高斯混合模型](https://www.mianshiya.com/tag/%E9%AB%98%E6%96%AF%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B)                                                                                                                                 |
|     | [说说 EM 算法。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834644157403138)                                       | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[聚类](https://www.mianshiya.com/tag/%E8%81%9A%E7%B1%BB)<br><br>[最大期望](https://www.mianshiya.com/tag/%E6%9C%80%E5%A4%A7%E6%9C%9F%E6%9C%9B)<br><br>[数学](https://www.mianshiya.com/tag/%E6%95%B0%E5%AD%A6)                                                                                       |
|     | [请描述支持向量机（svm）的基本思想和应用场景。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834644434227202)                        | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)                                                                                                                                                                                                                                                     |
|     | [svm 可以处理多分类吗？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834644706856961)                                   | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)<br><br>[分类](https://www.mianshiya.com/tag/%E5%88%86%E7%B1%BB)                                                                                                                                                                                       |
|     | [软间隔和硬间隔有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834645017235458)                                   | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)                                                                                                                                                                                                                                                     |
|     | [svm 与感知机有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834645315031042)                                  | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)<br><br>[感知机](https://www.mianshiya.com/tag/%E6%84%9F%E7%9F%A5%E6%9C%BA)                                                                                                                                                                             |
|     | [简单说说核函数的原理。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834645583466498)                                     | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)<br><br>[核函数](https://www.mianshiya.com/tag/%E6%A0%B8%E5%87%BD%E6%95%B0)                                                                                                                                                                             |
|     | [svm 有哪些核函数？分别应用于哪些场景中？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834645872873474)                          | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)<br><br>[核函数](https://www.mianshiya.com/tag/%E6%A0%B8%E5%87%BD%E6%95%B0)                                                                                                                                                                             |
|     | [svm 在应用高斯核时需要对特征进行归一化吗？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834646145503234)                         | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[svm](https://www.mianshiya.com/tag/svm)<br><br>[核函数](https://www.mianshiya.com/tag/%E6%A0%B8%E5%87%BD%E6%95%B0)                                                                                                                                                                             |
|     | [简单描述朴素贝叶斯的算法流程。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834646426521602)                                 | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[朴素贝叶斯](https://www.mianshiya.com/tag/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)<br><br>[数学](https://www.mianshiya.com/tag/%E6%95%B0%E5%AD%A6)                                                                                                                                           |
|     | [朴素贝叶斯常见的分类模型是什么？请分别说明。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834646678179841)                          | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[朴素贝叶斯](https://www.mianshiya.com/tag/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)<br><br>[分类](https://www.mianshiya.com/tag/%E5%88%86%E7%B1%BB)                                                                                                                                           |
|     | [朴素贝叶斯中的零概率问题是什么？如何应对？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834646992752641)                           | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[朴素贝叶斯](https://www.mianshiya.com/tag/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)                                                                                                                                                                                                         |
|     | [为什么朴素贝叶斯是高偏差低方差？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834647303131138)                                | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[朴素贝叶斯](https://www.mianshiya.com/tag/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)                                                                                                                                                                                                         |
|     | [朴素贝叶斯如何应对高度相关的特征？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834647575760897)                               | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[朴素贝叶斯](https://www.mianshiya.com/tag/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF)                                                                                                                                                                                                         |
|     | [说说构造决策树的步骤。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834647869362177)                                     | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)                                                                                                                                                                                                                             |
|     | [决策树是否可以处理非数值型特征？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834648129409026)                                | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)                                                                                                                                                                                                                             |
|     | [决策树算法是如何应对欠拟合和过拟合的？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834648381067266)                             | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)<br><br>[欠拟合](https://www.mianshiya.com/tag/%E6%AC%A0%E6%8B%9F%E5%90%88)<br><br>[过拟合](https://www.mianshiya.com/tag/%E8%BF%87%E6%8B%9F%E5%90%88)                                                                             |
|     | [分别说说 ID3、C4.5 和 CART 算法。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834648649502721)                        | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)<br><br>[ID3 算法](https://www.mianshiya.com/tag/ID3%20%E7%AE%97%E6%B3%95)<br><br>[C4.5 算法](https://www.mianshiya.com/tag/C4.5%20%E7%AE%97%E6%B3%95)<br><br>[CART 算法](https://www.mianshiya.com/tag/CART%20%E7%AE%97%E6%B3%95) |
|     | [既然 ID3 算法中已经选择了信息增益，为何 C4.5 算法中选择使用信息增益率？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834648922132481)       | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)<br><br>[ID3 算法](https://www.mianshiya.com/tag/ID3%20%E7%AE%97%E6%B3%95)<br><br>[C4.5 算法](https://www.mianshiya.com/tag/C4.5%20%E7%AE%97%E6%B3%95)                                                                           |
|     | [分别描述 C4.5 算法中预剪枝和后剪枝的策略，并说说和 CART 算法中的剪枝策略有何不同？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834649203150850) | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)<br><br>[C4.5 算法](https://www.mianshiya.com/tag/C4.5%20%E7%AE%97%E6%B3%95)<br><br>[CART 算法](https://www.mianshiya.com/tag/CART%20%E7%AE%97%E6%B3%95)<br><br>[剪枝](https://www.mianshiya.com/tag/%E5%89%AA%E6%9E%9D)           |
|     | [为什么 CART 算法特征选择方式是基尼系数，而不是信息熵？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834649454809090)                  | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)<br><br>[CART 算法](https://www.mianshiya.com/tag/CART%20%E7%AE%97%E6%B3%95)                                                                                                                                                   |
|     | [请简要描述随机森林算法的过程。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834649727438849)                                 | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[随机森林](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)<br><br>[集成学习](https://www.mianshiya.com/tag/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)                                                         |
|     | [随机森林算法为什么不使用全样本训练 m 棵决策树？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834649983291393)                       | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[随机森林](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)<br><br>[集成学习](https://www.mianshiya.com/tag/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)                                                         |
|     | [如何理解随机森林的随机性？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834650281086977)                                   | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[随机森林](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)                                                                                                                                                                                                                   |
|     | [随机森林算法是否容易过拟合？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834650562105345)                                  | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[随机森林](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)<br><br>[过拟合](https://www.mianshiya.com/tag/%E8%BF%87%E6%8B%9F%E5%90%88)                                                                                                                                           |
|     | [解释 Boosting 算法和 Bagging 算法的区别。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834650834735106)                  | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Boosting 算法](https://www.mianshiya.com/tag/Boosting%20%E7%AE%97%E6%B3%95)<br><br>[Bagging 算法](https://www.mianshiya.com/tag/Bagging%20%E7%AE%97%E6%B3%95)                                                                                                                                   |
|     | [简述 Adaboost 算法的原理。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834651107364865)                              | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Adaboost 算法](https://www.mianshiya.com/tag/Adaboost%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                   |
|     | [如何使用 Adaboost 算法进行特征选择？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834651367411713)                         | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Adaboost 算法](https://www.mianshiya.com/tag/Adaboost%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                   |
|     | [Adaboost 算法对噪声敏感吗？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834651702956033)                              | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Adaboost 算法](https://www.mianshiya.com/tag/Adaboost%20%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                   |
|     | [Adaboost 算法和随机森林算法有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834651967197185)                        | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Adaboost 算法](https://www.mianshiya.com/tag/Adaboost%20%E7%AE%97%E6%B3%95)<br><br>[随机森林算法](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%AE%97%E6%B3%95)                                                                                                             |
|     | [什么是 Gradient Boosting？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834652227244033)                          | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Gradient Boosting](https://www.mianshiya.com/tag/Gradient%20Boosting)                                                                                                                                                                                                                       |
|     | [Gradient Boosting 为什么不使用决策树桩？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834652504068098)                   | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Gradient Boosting](https://www.mianshiya.com/tag/Gradient%20Boosting)<br><br>[决策树](https://www.mianshiya.com/tag/%E5%86%B3%E7%AD%96%E6%A0%91)                                                                                                                                               |
|     | [Gradient Boosting 与 XGBoost 有什么区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834652789280770)              | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[Gradient Boosting](https://www.mianshiya.com/tag/Gradient%20Boosting)<br><br>[XGBoost](https://www.mianshiya.com/tag/XGBoost)                                                                                                                                                               |
|     | [解释 GBDT(Gradient Boosted Decision Trees) 原理。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834653066104833)    | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[GBDT](https://www.mianshiya.com/tag/GBDT)                                                                                                                                                                                                                                                   |
|     | [GBDT 适合使用高维稀疏特征吗？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834653347123201)                               | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[GBDT](https://www.mianshiya.com/tag/GBDT)                                                                                                                                                                                                                                                   |
|     | [GBDT 可以用于分类任务吗？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834653682667522)                                 | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[GBDT](https://www.mianshiya.com/tag/GBDT)<br><br>[分类](https://www.mianshiya.com/tag/%E5%88%86%E7%B1%BB)                                                                                                                                                                                     |
|     | [解释什么是降维，以及为什么要降维。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834653946908674)                               | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)<br><br>[奇异值](https://www.mianshiya.com/tag/%E5%A5%87%E5%BC%82%E5%80%BC)                                                                                                                                                               |
|     | [降维有哪些优缺点？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834654223732738)                                       | 简单  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)                                                                                                                                                                                                                                       |
|     | [说说什么是奇异值分解？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834654550888450)                                     | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[奇异值](https://www.mianshiya.com/tag/%E5%A5%87%E5%BC%82%E5%80%BC)                                                                                                                                                                                                                             |
|     | [奇异值分解在降维中有什么作用？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834654794158082)                                 | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)<br><br>[奇异值](https://www.mianshiya.com/tag/%E5%A5%87%E5%BC%82%E5%80%BC)                                                                                                                                                               |
|     | [特征值和奇异值的区别是什么？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834655083565057)                                  | 困难  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[奇异值](https://www.mianshiya.com/tag/%E5%A5%87%E5%BC%82%E5%80%BC)                                                                                                                                                                                                                             |
|     | [解释 PCA 算法的原理和步骤。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834655364583426)                                | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[PCA](https://www.mianshiya.com/tag/PCA)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)                                                                                                                                                                                       |
|     | [如何确定 PCA 降维之后的维度？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834655683350529)                               | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[PCA](https://www.mianshiya.com/tag/PCA)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)                                                                                                                                                                                       |
|     | [介绍一下 LDA 算法。](https://www.mianshiya.com/bank/1821834636175642625/question/1821834656002117633)                                    | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[LDA](https://www.mianshiya.com/tag/LDA)<br><br>[降维](https://www.mianshiya.com/tag/%E9%99%8D%E7%BB%B4)                                                                                                                                                                                       |
|     | [PCA 和 LDA 有哪些区别？](https://www.mianshiya.com/bank/1821834636175642625/question/1821834656312496130)                                | 中等  | [机器学习](https://www.mianshiya.com/tag/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0)<br><br>[LDA](https://www.mianshiya.com/tag/LDA)<br><br>[PCA](https://www.mianshiya.com/tag/PCA)                                                                                                                                                                                                     |
