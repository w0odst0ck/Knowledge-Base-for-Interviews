| 标记  | 题目                                                                                                                                        | 难度  | 标签                                                                                                                                                                                                                                                                                                                                                                                               |
| --- | ----------------------------------------------------------------------------------------------------------------------------------------- | --- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
|     |                                                                                                                                           |     |                                                                                                                                                                                                                                                                                                                                                                                                  |
|     | [什么是深度学习？它与传统机器学习有什么区别？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834656803229697)                                 | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[概念](https://www.mianshiya.com/tag/%E6%A6%82%E5%BF%B5)                                                                                                                                                                                                                                                         |
|     | [如何评估一个深度学习模型的性能？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834657075859457)                                       | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)                                                                                                                                                                                                                                                                                                                       |
|     | [解释权重初始化对深度学习模型的作用。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834657361072129)                                     | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)                                                                                                                                                                                                                                                                                                                       |
|     | [有了解过哪些边缘端部署方案？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834657642090497)                                         | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[部署](https://www.mianshiya.com/tag/%E9%83%A8%E7%BD%B2)                                                                                                                                                                                                                                                         |
|     | [解释是什么导致了梯度消失和梯度爆炸，以及应该如何应对它们。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834657944080386)                          | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[梯度](https://www.mianshiya.com/tag/%E6%A2%AF%E5%BA%A6)                                                                                                                                                                       |
|     | [神经网络中的 iteration 和 epoch 相同吗？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834658246070273)                          | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                                     |
|     | [如何确定神经网络的层数和神经元数？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834658564837377)                                      | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                                     |
|     | [激活函数在神经网络中有什么作用？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834658887798786)                                       | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[激活函数](https://www.mianshiya.com/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0)                                                                                                                                                   |
|     | [前向传播和反向传播在神经网络中分别是如何工作的？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834659164622849)                               | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[前向传播](https://www.mianshiya.com/tag/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD)<br><br>[反向传播](https://www.mianshiya.com/tag/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD)                                                                 |
|     | [神经网络有哪些正则化的操作？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834659428864001)                                         | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[正则化](https://www.mianshiya.com/tag/%E6%AD%A3%E5%88%99%E5%8C%96)                                                                                                                                                             |
|     | [前馈神经网络和循环神经网络的区别是什么？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834659776991234)                                   | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[前馈神经网络](https://www.mianshiya.com/tag/%E5%89%8D%E9%A6%88%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[循环神经网络](https://www.mianshiya.com/tag/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                           |
|     | [分别解释神经网络中的 Dropout 和 Batch Normalization 操作。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834660087369730)           | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[Dropout](https://www.mianshiya.com/tag/Dropout)<br><br>[Batch Normalization](https://www.mianshiya.com/tag/Batch%20Normalization)                                                                                           |
|     | [Batch Normalization 的作用是什么？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834660359999490)                            | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[Batch Normalization](https://www.mianshiya.com/tag/Batch%20Normalization)                                                                                                                                                   |
|     | [分别说说深度学习中的 Attention 机制和全连接层。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834660695543810)                          | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[神经网络](https://www.mianshiya.com/tag/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[Attention 机制](https://www.mianshiya.com/tag/Attention%20%E6%9C%BA%E5%88%B6)<br><br>[全连接层](https://www.mianshiya.com/tag/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82)                                                               |
|     | [你知道有哪些深度学习优化算法？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834661022699522)                                        | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[优化算法](https://www.mianshiya.com/tag/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                                     |
|     | [随机梯度下降可以用来做 online learning 吗？若可以，简述其过程。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834661295329282)               | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[优化算法](https://www.mianshiya.com/tag/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)<br><br>[随机梯度下降](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)                                                                                                                               |
|     | [简述动量梯度下降算法。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834661542793218)                                            | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[优化算法](https://www.mianshiya.com/tag/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)<br><br>[动量梯度下降](https://www.mianshiya.com/tag/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)                                                                                                                               |
|     | [随机梯度下降和 Adam 谁更容易达到全局最优解？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834661836394498)                              | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[优化算法](https://www.mianshiya.com/tag/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)<br><br>[随机梯度下降](https://www.mianshiya.com/tag/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)<br><br>[Adam](https://www.mianshiya.com/tag/Adam)                                                                             |
|     | [在选择优化器的过程中，主要看中哪些参数？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834662088052738)                                   | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[优化算法](https://www.mianshiya.com/tag/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)                                                                                                                                                                                                                                     |
|     | [深度学习调参的过程中，Batch 的大小如何选择？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834662348099586)                              | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)                                                                                                                                                                                                                                                                                                                       |
|     | [说说你对 ReLU 函数及其常见变体的认识。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834662612340738)                                 | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[激活函数](https://www.mianshiya.com/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0)<br><br>[ReLU 函数](https://www.mianshiya.com/tag/ReLU%20%E5%87%BD%E6%95%B0)                                                                                                                                                           |
|     | [ReLU 函数比 Sigmoid 和 tanh 函数更好吗？为什么？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834662914330625)                     | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[激活函数](https://www.mianshiya.com/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0)<br><br>[ReLU 函数](https://www.mianshiya.com/tag/ReLU%20%E5%87%BD%E6%95%B0)<br><br>[Sigmoid 函数](https://www.mianshiya.com/tag/Sigmoid%20%E5%87%BD%E6%95%B0)<br><br>[tanh 函数](https://www.mianshiya.com/tag/tanh%20%E5%87%BD%E6%95%B0) |
|     | [如何理解 ReLU 函数在输入小于 0 时输出为 0?](https://www.mianshiya.com/bank/1821834656568348674/question/1821834663182766082)                            | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[激活函数](https://www.mianshiya.com/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0)<br><br>[ReLU 函数](https://www.mianshiya.com/tag/ReLU%20%E5%87%BD%E6%95%B0)                                                                                                                                                           |
|     | [我们知道 ReLU 函数在 0 处不可导，这对于它在深度学习中的使用有什么影响吗？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834663480561666)              | 困难  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[激活函数](https://www.mianshiya.com/tag/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0)<br><br>[ReLU 函数](https://www.mianshiya.com/tag/ReLU%20%E5%87%BD%E6%95%B0)                                                                                                                                                           |
|     | [什么是卷积神经网络（CNN）？请描述其主要组件和应用。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834663786745858)                            | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [说说卷积层的基本参数。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834664059375617)                                            | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [如何理解卷积层的“深度”？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834664332005378)                                          | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [描述全连接层和卷积层的区别。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834664621412353)                                         | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[全连接层](https://www.mianshiya.com/tag/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82)                                                                                                                               |
|     | [分别解释二维卷积和三维卷积。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834664902430721)                                         | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [1×1 卷积有什么作用？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834665187643393)                                           | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [池化操作的原理是什么？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834665439301634)                                            | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[池化](https://www.mianshiya.com/tag/%E6%B1%A0%E5%8C%96)                                                                                                                                                   |
|     | [卷积核越大越好吗？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834665728708610)                                              | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [有哪些方法可以减少卷积层参数量？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834666005532673)                                       | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [如何理解卷积神经网络中的感受野？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834666248802306)                                       | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[感受野](https://www.mianshiya.com/tag/%E6%84%9F%E5%8F%97%E9%87%8E)                                                                                                                                         |
|     | [卷积神经网络是如何处理过拟合问题的？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834666571763714)                                     | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[过拟合](https://www.mianshiya.com/tag/%E8%BF%87%E6%8B%9F%E5%90%88)                                                                                                                                         |
|     | [卷积神经网络为什么比较适合做图像识别任务？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834666831810562)                                  | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[图像识别](https://www.mianshiya.com/tag/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB)                                                                                                                               |
|     | [什么是局部响应标准化（local response normalization），它可以用于卷积神经网络吗？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834667112828929) | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[局部响应标准化](https://www.mianshiya.com/tag/%E5%B1%80%E9%83%A8%E5%93%8D%E5%BA%94%E6%A0%87%E5%87%86%E5%8C%96)                                                                                                 |
|     | [请你解释步长（stride）的概念，以及它是如何影响卷积层输出大小的。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834667389652993)                    | 简单  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[步长](https://www.mianshiya.com/tag/%E6%AD%A5%E9%95%BF)                                                                                                                                                   |
|     | [什么是循环神经网络（RNN）？请描述其特点和局限性。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834667649699842)                             | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[循环神经网络](https://www.mianshiya.com/tag/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
|     | [卷积神经网络和循环神经网络（RNN）有什么区别？](https://www.mianshiya.com/bank/1821834656568348674/question/1821834667905552386)                               | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[循环神经网络](https://www.mianshiya.com/tag/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)<br><br>[卷积神经网络](https://www.mianshiya.com/tag/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)                                                                                                           |
|     | [请解释生成对抗网络（GAN）的基本原理和应用场景。](https://www.mianshiya.com/bank/1821834656568348674/question/1821834668173987842)                              | 中等  | [深度学习](https://www.mianshiya.com/tag/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)<br><br>[生成对抗网络](https://www.mianshiya.com/tag/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C)                                                                                                                                                                                                                 |
